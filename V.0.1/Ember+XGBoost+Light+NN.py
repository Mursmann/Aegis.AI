import os
import ember
import numpy as np
import lightgbm as lgb
import xgboost as xgb
from sklearn.metrics import classification_report, roc_auc_score
import joblib
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import psutil
import time
import lief
import logging  


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()  
    ]
)
def analyze_python_file(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read().lower()
        suspicious_keywords = ["mining", "stratum", "pyminer", "cryptocurrency"]
        if any(keyword in content for keyword in suspicious_keywords):
            logging.warning(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π Python —Ñ–∞–π–ª: {file_path}")
            return True
        logging.info(f"‚úÖ Python —Ñ–∞–π–ª –±–µ–∑–æ–ø–∞—Å–µ–Ω: {file_path}")
        return False
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Python —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return False
def preprocess_labels(y):
    y = np.where(y == -1, 0, y)  
    return y.astype(np.float32)  

def train_models():
    EMBER_PATH = "ember2018"
    X_TRAIN_PATH = os.path.join(EMBER_PATH, "X_train.dat")
    X_TEST_PATH = os.path.join(EMBER_PATH, "X_test.dat")

    if not (os.path.exists(X_TRAIN_PATH) and os.path.exists(X_TEST_PATH)):
        logging.info("üîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        ember.create_vectorized_features(EMBER_PATH)
    else:
        logging.info("‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ.")

    logging.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
    X_train, y_train, X_test, y_test = ember.read_vectorized_features(EMBER_PATH)

    logging.info("üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–æ–∫...")
    y_train = preprocess_labels(y_train)
    y_test = preprocess_labels(y_test)

    logging.info("üß† –û–±—É—á–µ–Ω–∏–µ LightGBM...")
    dtrain = lgb.Dataset(X_train, label=y_train)
    params_lgb = {"objective": "binary", "metric": "auc"}
    model_lgb = lgb.train(params_lgb, dtrain)

    y_pred_lgb = model_lgb.predict(X_test)
    y_pred_lgb_binary = (y_pred_lgb > 0.5).astype(int)
    logging.info("üìä LightGBM Classification Report:")
    logging.info("\n%s", classification_report(y_test, y_pred_lgb_binary))
    logging.info("LightGBM ROC-AUC: %s", roc_auc_score(y_test, y_pred_lgb))

    logging.info("üß† –û–±—É—á–µ–Ω–∏–µ XGBoost...")
    dtrain_xgb = xgb.DMatrix(X_train, label=y_train)
    dtest_xgb = xgb.DMatrix(X_test, label=y_test)
    params_xgb = {
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'max_depth': 6,
        'eta': 0.1,
        'seed': 42
    }
    model_xgb = xgb.train(params_xgb, dtrain_xgb, num_boost_round=100)

    y_pred_xgb = model_xgb.predict(dtest_xgb)
    y_pred_xgb_binary = (y_pred_xgb > 0.5).astype(int)
    logging.info("üìä XGBoost Classification Report:")
    logging.info("\n%s", classification_report(y_test, y_pred_xgb_binary))
    logging.info("XGBoost ROC-AUC: %s", roc_auc_score(y_test, y_pred_xgb))

    y_train_pred_lgb = model_lgb.predict(X_train)
    y_train_pred_xgb = model_xgb.predict(dtrain_xgb)
    y_test_pred_lgb = model_lgb.predict(X_test)
    y_test_pred_xgb = model_xgb.predict(dtest_xgb)

    X_meta_train = np.column_stack((y_train_pred_lgb, y_train_pred_xgb))
    y_meta_train = y_train
    X_meta_test = np.column_stack((y_test_pred_lgb, y_test_pred_xgb))
    y_meta_test = y_test

    logging.info("üß† –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ (–Ω–µ–π—Ä–æ—Å–µ—Ç–∏)...")
    meta_model = Sequential([
        Dense(10, activation='relu', input_shape=(X_meta_train.shape[1],)),
        Dense(1, activation='sigmoid')
    ])
    meta_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    meta_model.fit(X_meta_train, y_meta_train, epochs=10, batch_size=32, verbose=0)

    y_pred_meta = meta_model.predict(X_meta_test, verbose=0)
    y_pred_meta_binary = (y_pred_meta > 0.5).astype(int)
    logging.info("üìä Meta-model Classification Report:")
    logging.info("\n%s", classification_report(y_meta_test, y_pred_meta_binary))
    logging.info("Meta-model ROC-AUC: %s", roc_auc_score(y_meta_test, y_pred_meta))

    joblib.dump(model_lgb, "ember_model_lgb.lgb")
    model_xgb.save_model("xgb_model.json")
    meta_model.save("meta_model.h5")
    logging.info("‚úÖ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")

def extract_features(file_path):
    try:
        logging.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞: {file_path}")
        if not lief.is_pe(file_path):
            logging.warning(f"{file_path} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º PE-—Ñ–∞–π–ª–æ–º")
            return None
        with open(file_path, "rb") as f:
            binary = f.read()
        extractor = ember.PEFeatureExtractor()
        features = np.array(extractor.feature_vector(binary), dtype=np.float32)
        logging.info(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏–∑ {file_path}")
        return features
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ {file_path}: {e}")
        return None

def monitor_system():
    logging.info("üöÄ –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞...")
    try:
        model_lgb = joblib.load("ember_model_lgb.lgb")
        model_xgb = xgb.Booster()
        model_xgb.load_model("xgb_model.json")
        model_meta = tf.keras.models.load_model("meta_model.h5")
        logging.info("‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
        return

    MONITOR_DIR = "lessons_space"  
    checked_files = set() 
    MINING_POOLS = ["pool.minergate.com", "xmr.pool.minergate.com", "pool.nicehash.com"]

    while True:
        try:
            exe_files = [f for f in os.listdir(MONITOR_DIR) if f.endswith(".exe") and f not in checked_files]
            py_files = [f for f in os.listdir(MONITOR_DIR) if f.endswith(".py") and f not in checked_files]
            if not exe_files and not py_files:
                logging.info(f"–í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {MONITOR_DIR} –Ω–µ—Ç –Ω–æ–≤—ã—Ö .exe –∏–ª–∏ .py —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            for file in exe_files:
                file_path = os.path.join(MONITOR_DIR, file)
                features = extract_features(file_path)
                if features is not None:
                    features = np.array(features).reshape(1, -1)
                    y_pred_lgb = model_lgb.predict(features)
                    dtest_xgb = xgb.DMatrix(features)
                    y_pred_xgb = model_xgb.predict(dtest_xgb)
                    X_meta = np.column_stack((y_pred_lgb, y_pred_xgb))
                    y_pred_meta = model_meta.predict(X_meta, verbose=0)
                    if y_pred_meta[0] > 0.5:
                        logging.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
                    else:
                        logging.info(f"‚úÖ –§–∞–π–ª –±–µ–∑–æ–ø–∞—Å–µ–Ω: {file_path}")
                checked_files.add(file)
            for file in py_files:
                file_path = os.path.join(MONITOR_DIR, file)
                if analyze_python_file(file_path):
                    logging.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π Python —Ñ–∞–π–ª: {file_path}")
                else:
                    logging.info(f"‚úÖ Python —Ñ–∞–π–ª –±–µ–∑–æ–ø–∞—Å–µ–Ω: {file_path}")
                checked_files.add(file)

            for proc in psutil.process_iter(['name', 'exe', 'cpu_percent']):
                try:
                    if proc.info['cpu_percent'] > 80:  
                        file_path = proc.info['exe']
                        if file_path and file_path.endswith(".exe"):
                            features = extract_features(file_path)
                            if features is not None:
                                features = np.array(features).reshape(1, -1)
                                y_pred_lgb = model_lgb.predict(features)
                                dtest_xgb = xgb.DMatrix(features)
                                y_pred_xgb = model_xgb.predict(dtest_xgb)
                                X_meta = np.column_stack((y_pred_lgb, y_pred_xgb))
                                y_pred_meta = model_meta.predict(X_meta, verbose=0)
                                if y_pred_meta[0] > 0.5:
                                    logging.warning(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å: {proc.info['name']}")
                                    proc.terminate()
                    net_connections = proc.net_connections() if hasattr(proc, 'net_connections') else []
                    for conn in net_connections:
                        if conn.raddr and any(pool in conn.raddr.ip for pool in MINING_POOLS):
                            logging.warning(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ —Å–µ—Ç–µ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ: {proc.info['name']} -> {conn.raddr.ip}")
                            proc.terminate()
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ {proc.info['name']}: {e}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
        time.sleep(10)  

if __name__ == "__main__":
    from multiprocessing import freeze_support
    freeze_support()
    # train_models()  
    monitor_system()
