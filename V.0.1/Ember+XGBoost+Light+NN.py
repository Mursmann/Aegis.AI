import os
import ember
import numpy as np
import lightgbm as lgb
import xgboost as xgb
from sklearn.metrics import classification_report, roc_auc_score
import joblib
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
import psutil
import time
import lief
import logging  


logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler()  
    ]
)
def analyze_python_file(file_path):
    try:
        with open(file_path, "r", encoding="utf-8") as f:
            content = f.read().lower()
        suspicious_keywords = ["mining", "stratum", "pyminer", "cryptocurrency"]
        if any(keyword in content for keyword in suspicious_keywords):
            logging.warning(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π Python —Ñ–∞–π–ª: {file_path}")
            return True
        logging.info(f"‚úÖ Python —Ñ–∞–π–ª –±–µ–∑–æ–ø–∞—Å–µ–Ω: {file_path}")
        return False
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞ Python —Ñ–∞–π–ª–∞ {file_path}: {e}")
        return False
def preprocess_labels(y):
    """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –º–µ—Ç–∫–∏: -1 -> 0, –æ—Å—Ç–∞–≤–ª—è–µ—Ç 0 –∏ 1 –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π."""
    y = np.where(y == -1, 0, y)  # –ó–∞–º–µ–Ω—è–µ–º -1 –Ω–∞ 0 (–Ω–µ–∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ -> –±–µ–∑–æ–ø–∞—Å–Ω—ã–µ)
    return y.astype(np.float32)  # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ –º–µ—Ç–∫–∏ –≤ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ

def train_models():
    EMBER_PATH = "C:/Users/Vovaaaan/Downloads/ember_dataset_2018_2/ember2018"
    X_TRAIN_PATH = os.path.join(EMBER_PATH, "X_train.dat")
    X_TEST_PATH = os.path.join(EMBER_PATH, "X_test.dat")

    # === –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ ===
    if not (os.path.exists(X_TRAIN_PATH) and os.path.exists(X_TEST_PATH)):
        logging.info("üîß –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤...")
        ember.create_vectorized_features(EMBER_PATH)
    else:
        logging.info("‚úÖ –ü—Ä–∏–∑–Ω–∞–∫–∏ —É–∂–µ —Å–æ–∑–¥–∞–Ω—ã, –ø—Ä–æ–ø—É—Å–∫–∞–µ–º —Å–æ–∑–¥–∞–Ω–∏–µ.")

    # === –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
    logging.info("üì¶ –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—É—á–∞—é—â–∏—Ö –¥–∞–Ω–Ω—ã—Ö...")
    X_train, y_train, X_test, y_test = ember.read_vectorized_features(EMBER_PATH)

    # === –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–æ–∫ ===
    logging.info("üîÑ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–æ–∫...")
    y_train = preprocess_labels(y_train)
    y_test = preprocess_labels(y_test)

    # === –û–±—É—á–µ–Ω–∏–µ LightGBM ===
    logging.info("üß† –û–±—É—á–µ–Ω–∏–µ LightGBM...")
    dtrain = lgb.Dataset(X_train, label=y_train)
    params_lgb = {"objective": "binary", "metric": "auc"}
    model_lgb = lgb.train(params_lgb, dtrain)

    # === –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è LightGBM ===
    y_pred_lgb = model_lgb.predict(X_test)
    y_pred_lgb_binary = (y_pred_lgb > 0.5).astype(int)
    logging.info("üìä LightGBM Classification Report:")
    logging.info("\n%s", classification_report(y_test, y_pred_lgb_binary))
    logging.info("LightGBM ROC-AUC: %s", roc_auc_score(y_test, y_pred_lgb))

    # === –û–±—É—á–µ–Ω–∏–µ XGBoost ===
    logging.info("üß† –û–±—É—á–µ–Ω–∏–µ XGBoost...")
    dtrain_xgb = xgb.DMatrix(X_train, label=y_train)
    dtest_xgb = xgb.DMatrix(X_test, label=y_test)
    params_xgb = {
        'objective': 'binary:logistic',
        'eval_metric': 'auc',
        'max_depth': 6,
        'eta': 0.1,
        'seed': 42
    }
    model_xgb = xgb.train(params_xgb, dtrain_xgb, num_boost_round=100)

    # === –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è XGBoost ===
    y_pred_xgb = model_xgb.predict(dtest_xgb)
    y_pred_xgb_binary = (y_pred_xgb > 0.5).astype(int)
    logging.info("üìä XGBoost Classification Report:")
    logging.info("\n%s", classification_report(y_test, y_pred_xgb_binary))
    logging.info("XGBoost ROC-AUC: %s", roc_auc_score(y_test, y_pred_xgb))

    # === –ü–æ–ª—É—á–µ–Ω–∏–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–π –¥–ª—è –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ ===
    y_train_pred_lgb = model_lgb.predict(X_train)
    y_train_pred_xgb = model_xgb.predict(dtrain_xgb)
    y_test_pred_lgb = model_lgb.predict(X_test)
    y_test_pred_xgb = model_xgb.predict(dtest_xgb)

    # === –°–æ–∑–¥–∞–Ω–∏–µ –Ω–∞–±–æ—Ä–æ–≤ –¥–ª—è –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ ===
    X_meta_train = np.column_stack((y_train_pred_lgb, y_train_pred_xgb))
    y_meta_train = y_train
    X_meta_test = np.column_stack((y_test_pred_lgb, y_test_pred_xgb))
    y_meta_test = y_test

    # === –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ (–Ω–µ–π—Ä–æ—Å–µ—Ç–∏) ===
    logging.info("üß† –û–±—É—á–µ–Ω–∏–µ –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ (–Ω–µ–π—Ä–æ—Å–µ—Ç–∏)...")
    meta_model = Sequential([
        Dense(10, activation='relu', input_shape=(X_meta_train.shape[1],)),
        Dense(1, activation='sigmoid')
    ])
    meta_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
    meta_model.fit(X_meta_train, y_meta_train, epochs=10, batch_size=32, verbose=0)

    # === –ü—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è –º–µ—Ç–∞-–º–æ–¥–µ–ª–∏ ===
    y_pred_meta = meta_model.predict(X_meta_test, verbose=0)
    y_pred_meta_binary = (y_pred_meta > 0.5).astype(int)
    logging.info("üìä Meta-model Classification Report:")
    logging.info("\n%s", classification_report(y_meta_test, y_pred_meta_binary))
    logging.info("Meta-model ROC-AUC: %s", roc_auc_score(y_meta_test, y_pred_meta))

    # === –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π ===
    joblib.dump(model_lgb, "ember_model_lgb.lgb")
    model_xgb.save_model("xgb_model.json")
    meta_model.save("meta_model.h5")
    logging.info("‚úÖ –ú–æ–¥–µ–ª–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã.")

def extract_features(file_path):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –ø—Ä–∏–∑–Ω–∞–∫–∏ –∏–∑ PE-—Ñ–∞–π–ª–∞ —Å –ø–æ–º–æ—â—å—é ember."""
    try:
        logging.info(f"–ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–∞–π–ª–∞: {file_path}")
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —è–≤–ª—è–µ—Ç—Å—è –ª–∏ —Ñ–∞–π–ª –≤–∞–ª–∏–¥–Ω—ã–º PE-—Ñ–∞–π–ª–æ–º
        if not lief.is_pe(file_path):
            logging.warning(f"{file_path} –Ω–µ —è–≤–ª—è–µ—Ç—Å—è –≤–∞–ª–∏–¥–Ω—ã–º PE-—Ñ–∞–π–ª–æ–º")
            return None
        with open(file_path, "rb") as f:
            binary = f.read()
        extractor = ember.PEFeatureExtractor()
        features = np.array(extractor.feature_vector(binary), dtype=np.float32)
        logging.info(f"–ü—Ä–∏–∑–Ω–∞–∫–∏ —É—Å–ø–µ—à–Ω–æ –∏–∑–≤–ª–µ—á–µ–Ω—ã –∏–∑ {file_path}")
        return features
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –∏–∑ {file_path}: {e}")
        return None

def monitor_system():
    logging.info("üöÄ –ó–∞–ø—É—Å–∫ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞...")
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π
    try:
        model_lgb = joblib.load("ember_model_lgb.lgb")
        model_xgb = xgb.Booster()
        model_xgb.load_model("xgb_model.json")
        model_meta = tf.keras.models.load_model("meta_model.h5")
        logging.info("‚úÖ –ú–æ–¥–µ–ª–∏ —É—Å–ø–µ—à–Ω–æ –∑–∞–≥—Ä—É–∂–µ–Ω—ã.")
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–µ–π: {e}")
        return

    MONITOR_DIR = "C:/Users/Vovaaaan/Desktop/lessons_space"  # –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    checked_files = set()  # –ß—Ç–æ–±—ã –Ω–µ –ø—Ä–æ–≤–µ—Ä—è—Ç—å —Ñ–∞–π–ª—ã –ø–æ–≤—Ç–æ—Ä–Ω–æ
    MINING_POOLS = ["pool.minergate.com", "xmr.pool.minergate.com", "pool.nicehash.com"]  # –°–ø–∏—Å–æ–∫ –º–∞–π–Ω–∏–Ω–≥–æ–≤—ã—Ö –ø—É–ª–æ–≤

    while True:
        try:
                        # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –Ω–æ–≤—ã—Ö —Ñ–∞–π–ª–æ–≤
            exe_files = [f for f in os.listdir(MONITOR_DIR) if f.endswith(".exe") and f not in checked_files]
            py_files = [f for f in os.listdir(MONITOR_DIR) if f.endswith(".py") and f not in checked_files]
            if not exe_files and not py_files:
                logging.info(f"–í –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ {MONITOR_DIR} –Ω–µ—Ç –Ω–æ–≤—ã—Ö .exe –∏–ª–∏ .py —Ñ–∞–π–ª–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏")
            for file in exe_files:
                file_path = os.path.join(MONITOR_DIR, file)
                features = extract_features(file_path)
                if features is not None:
                    features = np.array(features).reshape(1, -1)
                    y_pred_lgb = model_lgb.predict(features)
                    dtest_xgb = xgb.DMatrix(features)
                    y_pred_xgb = model_xgb.predict(dtest_xgb)
                    X_meta = np.column_stack((y_pred_lgb, y_pred_xgb))
                    y_pred_meta = model_meta.predict(X_meta, verbose=0)
                    if y_pred_meta[0] > 0.5:
                        logging.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –≤—Ä–µ–¥–æ–Ω–æ—Å–Ω—ã–π —Ñ–∞–π–ª: {file_path}")
                    else:
                        logging.info(f"‚úÖ –§–∞–π–ª –±–µ–∑–æ–ø–∞—Å–µ–Ω: {file_path}")
                checked_files.add(file)
            for file in py_files:
                file_path = os.path.join(MONITOR_DIR, file)
                if analyze_python_file(file_path):
                    logging.warning(f"‚ö†Ô∏è –û–±–Ω–∞—Ä—É–∂–µ–Ω –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π Python —Ñ–∞–π–ª: {file_path}")
                else:
                    logging.info(f"‚úÖ Python —Ñ–∞–π–ª –±–µ–∑–æ–ø–∞—Å–µ–Ω: {file_path}")
                checked_files.add(file)

            # –ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ (–¥–ª—è –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏—è –º–∞–π–Ω–∏–Ω–≥–∞)
            for proc in psutil.process_iter(['name', 'exe', 'cpu_percent']):
                try:
                    if proc.info['cpu_percent'] > 80:  # –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ –≤—ã—Å–æ–∫–∞—è –Ω–∞–≥—Ä—É–∑–∫–∞
                        file_path = proc.info['exe']
                        if file_path and file_path.endswith(".exe"):
                            features = extract_features(file_path)
                            if features is not None:
                                features = np.array(features).reshape(1, -1)
                                y_pred_lgb = model_lgb.predict(features)
                                dtest_xgb = xgb.DMatrix(features)
                                y_pred_xgb = model_xgb.predict(dtest_xgb)
                                X_meta = np.column_stack((y_pred_lgb, y_pred_xgb))
                                y_pred_meta = model_meta.predict(X_meta, verbose=0)
                                if y_pred_meta[0] > 0.5:
                                    logging.warning(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å: {proc.info['name']}")
                                    proc.terminate()
                                    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –æ–ø–æ–≤–µ—â–µ–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä, email)
                    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å–µ—Ç–µ–≤–æ–π –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ (–¥–ª—è –º–∞–π–Ω–∏–Ω–≥–∞)
                    net_connections = proc.net_connections() if hasattr(proc, 'net_connections') else []
                    for conn in net_connections:
                        if conn.raddr and any(pool in conn.raddr.ip for pool in MINING_POOLS):
                            logging.warning(f"‚ö†Ô∏è –ü–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ–µ —Å–µ—Ç–µ–≤–æ–µ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ: {proc.info['name']} -> {conn.raddr.ip}")
                            proc.terminate()
                except Exception as e:
                    logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –ø—Ä–æ—Ü–µ—Å—Å–∞ {proc.info['name']}: {e}")
        except Exception as e:
            logging.error(f"–û—à–∏–±–∫–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞: {e}")
        time.sleep(10)  # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–∞–∂–¥—ã–µ 10 —Å–µ–∫—É–Ω–¥

if __name__ == "__main__":
    from multiprocessing import freeze_support
    freeze_support()
    # train_models()  # –†–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
    monitor_system()
